# -*- coding: utf-8 -*-
"""Phase2_pythoncode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NbXO9B2Yns5vJYRJUvOyrbbmME9S1DkH

Upload the Dataset
"""

from google.colab import files
uploaded = files.upload()

"""Load the Dataset"""

import pandas as pd
# Read the dataset
df = pd.read_csv('english_movies.csv')

"""Data Exploration"""

# --- Data Exploration for english_movies.csv ---

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv("english_movies.csv")

# Basic info
print("Shape:", df.shape)
print("\nData Types:\n", df.dtypes)
print("\nMissing Values:\n", df.isnull().sum())
print("\nSample Records:\n", df.head())

# --- Descriptive Stats ---
print("\nStatistical Summary:\n", df.describe())

# --- Missing Value Handling (Optional) ---
# You might want to drop or fill missing values
df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')

# --- Genre Analysis ---
df['genres_list'] = df['genres'].fillna("").apply(lambda x: [g.strip() for g in x.split(',')])
all_genres = df['genres_list'].explode()
top_genres = all_genres.value_counts().head(10)

plt.figure(figsize=(10,5))
sns.barplot(x=top_genres.values, y=top_genres.index, palette="viridis")
plt.title("Top 10 Genres")
plt.xlabel("Number of Movies")
plt.show()

# --- Vote Average vs Popularity ---
plt.figure(figsize=(8,6))
sns.scatterplot(data=df, x='popularity', y='vote_average', size='vote_count', alpha=0.6)
plt.title("Popularity vs. Vote Average")
plt.xlabel("Popularity")
plt.ylabel("Vote Average")
plt.show()

# --- Correlation Heatmap ---
plt.figure(figsize=(6,4))
sns.heatmap(df[['popularity', 'vote_average', 'vote_count']].corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Matrix")
plt.show()

# --- Most Popular Movies ---
top_popular = df.sort_values(by='popularity', ascending=False).head(10)
print("\nTop 10 Most Popular Movies:\n", top_popular[['title', 'popularity', 'vote_average']])

"""Check for Missing Values and Duplicates"""

import pandas as pd

# Load the dataset
df = pd.read_csv('english_movies.csv')

# Check for missing values
missing_values = df.isnull().sum()

# Check for duplicate rows
duplicate_rows = df.duplicated().sum()

# Display the results
print("Missing Values in Each Column:")
print(missing_values)
print("\nNumber of Duplicate Rows:")
print(duplicate_rows)

"""Visualize a Few Features"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv('english_movies.csv')

# Set plot style
sns.set(style="whitegrid")

# Histogram of vote_average
plt.figure(figsize=(8, 5))
sns.histplot(df['vote_average'], bins=20, kde=True, color='skyblue')
plt.title('Distribution of Vote Averages')
plt.xlabel('Vote Average')
plt.ylabel('Frequency')
plt.show()

# Histogram of vote_count
plt.figure(figsize=(8, 5))
sns.histplot(df['vote_count'], bins=20, kde=True, color='salmon')
plt.title('Distribution of Vote Counts')
plt.xlabel('Vote Count')
plt.ylabel('Frequency')
plt.show()

# Scatter plot of popularity vs vote_average
plt.figure(figsize=(8, 5))
sns.scatterplot(data=df, x='popularity', y='vote_average', alpha=0.6)
plt.title('Popularity vs Vote Average')
plt.xlabel('Popularity')
plt.ylabel('Vote Average')
plt.show()

"""Identify Target and Features"""

import pandas as pd

# Load the dataset
df = pd.read_csv('english_movies.csv')

# Display the column names
print("Available Columns:\n", df.columns.tolist())

# Define the target variable
target = 'vote_average'

# Define the features (drop the target and non-numeric or irrelevant columns)
features = df.drop(columns=[target, 'title', 'overview', 'release_date', 'genres'])

# Print the selected target and features
print("\nTarget Variable:")
print(target)

print("\nFeature Columns:")
print(features.columns.tolist())

"""Convert Categorical Columns to Numerical"""

import pandas as pd

# Load the dataset
df = pd.read_csv('english_movies.csv')

# Display categorical columns
categorical_columns = df.select_dtypes(include=['object']).columns
print("Categorical Columns:", list(categorical_columns))

# Apply one-hot encoding to categorical columns
df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

# Display the transformed DataFrame
print("\nTransformed DataFrame with Categorical Columns Converted to Numerical:")
print(df_encoded.head())

"""One-Hot Encoding"""

import pandas as pd

# Load the dataset
df = pd.read_csv('english_movies.csv')

# Identify categorical columns
categorical_cols = df.select_dtypes(include=['object']).columns
print("Categorical Columns for One-Hot Encoding:", list(categorical_cols))

# Apply One-Hot Encoding
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# Show the result
print("\nEncoded DataFrame (first 5 rows):")
print(df_encoded.head())

# Optional: save to new CSV
# df_encoded.to_csv('encoded_english_movies.csv', index=False)

"""Feature Scaling"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Load the dataset
df = pd.read_csv('english_movies.csv')

# For demonstration: drop rows with missing values (you could also fill them)
df = df.dropna()

# Example: define features (X) and target (y)
# Let's predict 'vote_average' based on other numerical features
X = df.drop(columns=['vote_average'])
y = df['vote_average']

# If there are categorical columns, use one-hot encoding
X = pd.get_dummies(X, drop_first=True)

# Perform train-test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Show the result
print("Train Features Shape:", X_train.shape)
print("Test Features Shape:", X_test.shape)
print("Train Labels Shape:", y_train.shape)
print("Test Labels Shape:", y_test.shape)

"""Train-Test Split"""

# Google Colab Executable: English Movies Linear Regression Model

# Step 1: Import Libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# Step 2: Upload File (you will be prompted in Colab)
from google.colab import files
uploaded = files.upload()

# Step 3: Load Data
df = pd.read_csv(next(iter(uploaded)))
print("Dataset loaded successfully!\n")

# Step 4: Handle Missing Values
df = df.dropna()
print(f"Data shape after dropping missing values: {df.shape}")

# Step 5: Define Features and Target
X = df.drop(columns=['vote_average'])
y = df['vote_average']

# Step 6: One-Hot Encoding for Categorical Columns
X = pd.get_dummies(X, drop_first=True)

# Step 7: Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 8: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Step 9: Model Building - Linear Regression
model = LinearRegression()
model.fit(X_train, y_train)

# Step 10: Predictions and Evaluation
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\nModel Evaluation:")
print(f"Mean Squared Error: {mse:.2f}")
print(f"R² Score: {r2:.2f}")

"""Model Building"""

# STEP 1: Upload file
from google.colab import files
uploaded = files.upload()

# STEP 2: Import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# STEP 3: Load the uploaded file (get filename from uploaded dict)
filename = next(iter(uploaded))
df = pd.read_csv(filename)

# STEP 4: Drop rows with missing critical fields
df = df.dropna(subset=['genres', 'popularity', 'vote_count', 'vote_average'])

# STEP 5: Convert genres to list
df['genres'] = df['genres'].astype(str).apply(lambda x: [genre.strip() for genre in x.split(',')])

# STEP 6: One-hot encode genres
mlb = MultiLabelBinarizer()
genre_dummies = pd.DataFrame(mlb.fit_transform(df['genres']), columns=mlb.classes_, index=df.index)

# STEP 7: Combine features and target
X = pd.concat([df[['popularity', 'vote_count']], genre_dummies], axis=1)
y = df['vote_average']

# STEP 8: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# STEP 9: Train model
model = LinearRegression()
model.fit(X_train, y_train)

# STEP 10: Predict and evaluate
y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# STEP 11: Output results
print("\nModel Evaluation Metrics:")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R² Score: {r2:.2f}")

"""Evaluation"""

# STEP 1: Upload CSV
from google.colab import files
uploaded = files.upload()

# STEP 2: Imports
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# STEP 3: Load data
filename = next(iter(uploaded))
df = pd.read_csv(filename)

# STEP 4: Data Cleaning
df = df.dropna(subset=['genres', 'popularity', 'vote_count', 'vote_average'])
df['genres'] = df['genres'].astype(str).apply(lambda x: [g.strip() for g in x.split(',')])

# STEP 5: Genre One-hot Encoding
mlb = MultiLabelBinarizer()
genre_dummies = pd.DataFrame(mlb.fit_transform(df['genres']), columns=mlb.classes_, index=df.index)

# STEP 6: Feature preparation
X = pd.concat([df[['popularity', 'vote_count']], genre_dummies], axis=1)
y = df['vote_average']

# STEP 7: Train-test split and model training
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = LinearRegression()
model.fit(X_train, y_train)

# STEP 8: Define a prediction function
def predict_vote_average(popularity, vote_count, genres_list):
    # Create input row with zeroes
    input_data = pd.DataFrame([0]*X.shape[1], index=X.columns).T
    input_data['popularity'] = popularity
    input_data['vote_count'] = vote_count

    # Mark the selected genres
    for genre in genres_list:
        if genre in input_data.columns:
            input_data[genre] = 1

    # Predict
    predicted_rating = model.predict(input_data)[0]
    return round(predicted_rating, 2)

# STEP 9: Example prediction
example_prediction = predict_vote_average(
    popularity=3000.0,
    vote_count=1500,
    genres_list=['Action', 'Adventure', 'Science Fiction']
)
print(f"Predicted vote_average: {example_prediction}")

"""Make Predictions from New Input"""

# Step 1: Install necessary packages (usually already available in Colab)
!pip install -q scikit-learn pandas

# Step 2: Import required libraries
import pandas as pd
from sklearn.preprocessing import MultiLabelBinarizer
from google.colab import files

# Step 3: Upload the CSV file
print("Please upload your 'english_movies.csv' file...")
uploaded = files.upload()

# Step 4: Read the uploaded CSV
import io
file_name = next(iter(uploaded))  # Get the uploaded file name
df = pd.read_csv(io.BytesIO(uploaded[file_name]))

# Step 5: Check the structure
print("Data loaded. Here's the first few rows:")
display(df.head())

# Step 6: Encode the 'genres' column
# Ensure genres column is string before splitting
df['genres'] = df['genres'].astype(str).apply(lambda x: x.split(', '))
mlb = MultiLabelBinarizer()
genres_encoded = pd.DataFrame(mlb.fit_transform(df['genres']), columns=mlb.classes_)

# Step 7: Process 'release_date' to datetime and extract year/month
df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
df['release_year'] = df['release_date'].dt.year
df['release_month'] = df['release_date'].dt.month

# Step 8: Combine everything
df_final = pd.concat([df.drop(columns=['genres']), genres_encoded], axis=1)

# Step 9: Show result
print("Encoded DataFrame:")
display(df_final.head())

# Optional: Save the processed file
df_final.to_csv("processed_movies.csv", index=False)
files.download("processed_movies.csv")

"""Convert to DataFrame and Encode"""

# STEP 1: Install dependencies
!pip install pandas scikit-learn --quiet

# STEP 2: Import required libraries
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from google.colab import files

# STEP 3: Upload CSV file
print("📂 Upload your CSV file...")
uploaded = files.upload()

# STEP 4: Read the uploaded file into a DataFrame
filename = list(uploaded.keys())[0]
df = pd.read_csv(filename)

print("\n✅ DataFrame loaded successfully!")
print("\n📊 Preview of the data:")
print(df.head())

# STEP 5: Identify categorical (object or string) columns
cat_cols = df.select_dtypes(include='object').columns.tolist()

print("\n🧠 Categorical columns to encode:", cat_cols)

# STEP 6: Encode categorical columns using LabelEncoder
label_encoders = {}

for col in cat_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

print("\n✅ Encoding complete!")
print("\n🔍 Encoded DataFrame preview:")
print(df.head())

# Optional: Save the encoded DataFrame to CSV
df.to_csv("encoded_dataset.csv", index=False)
print("\n💾 Encoded CSV saved as 'encoded_dataset.csv'")

"""Predict the Final Grade"""

# Step 1: Install necessary libraries
!pip install -q scikit-learn pandas matplotlib seaborn

# Step 2: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Step 3: Load data from file already uploaded to Colab's environment
df = pd.read_csv("/content/english_movies.csv")  # Replace with your filename if different

# Step 4: Display the dataset
print("Data preview:")
display(df.head())

# Example assumption: you're trying to predict 'vote_average' as a proxy for 'final grade'
# You can change this to whatever your actual target column is
target_column = 'vote_average'

# Step 5: Drop rows with missing target and encode necessary columns
df = df.dropna(subset=[target_column])
df['genres'] = df['genres'].astype(str).apply(lambda x: x.split(', '))
df = pd.get_dummies(df, columns=['release_date'], drop_first=True)  # optional if dates are present

# Use MultiLabelBinarizer for genres
from sklearn.preprocessing import MultiLabelBinarizer
mlb = MultiLabelBinarizer()
genre_dummies = pd.DataFrame(mlb.fit_transform(df['genres']), columns=mlb.classes_)
df = pd.concat([df.drop(columns=['genres']), genre_dummies], axis=1)

# Step 6: Separate features and target
X = df.drop(columns=[target_column, 'title', 'overview'])  # Drop non-numeric / unnecessary columns
y = df[target_column]

# Step 7: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 8: Train the model
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# Step 9: Predict and evaluate
y_pred = model.predict(X_test)

print("\nEvaluation Metrics:")
print("R² Score:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

# Step 10: Plot actual vs predicted
plt.figure(figsize=(8, 5))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted Vote Average (Final Grade)")
plt.grid(True)
plt.show()

"""Deployment-Building an Interactive App"""

# Step 1: Install required packages
!pip install -q gradio pandas scikit-learn

# Step 2: Import libraries
import pandas as pd
import numpy as np
import gradio as gr
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import MultiLabelBinarizer

# Step 3: Load and preprocess data
df = pd.read_csv("/content/english_movies.csv")  # Replace with your file path
df = df.dropna(subset=['vote_average'])
df['genres'] = df['genres'].astype(str).apply(lambda x: x.split(', '))
df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
df['release_year'] = df['release_date'].dt.year
df['release_month'] = df['release_date'].dt.month

mlb = MultiLabelBinarizer()
genre_encoded = pd.DataFrame(mlb.fit_transform(df['genres']), columns=mlb.classes_)
df = pd.concat([df.drop(columns=['genres', 'title', 'overview', 'release_date']), genre_encoded], axis=1)

X = df.drop(columns=['vote_average'])
y = df['vote_average']

# Train the model
model = RandomForestRegressor(random_state=42)
model.fit(X, y)

# Create the prediction function
def predict_movie_score(popularity, vote_count, release_year, release_month, genres):
    input_data = {
        'popularity': popularity,
        'vote_count': vote_count,
        'release_year': release_year,
        'release_month': release_month
    }
    input_df = pd.DataFrame([input_data])
    genre_input = pd.DataFrame([[1 if g in genres else 0 for g in mlb.classes_]], columns=mlb.classes_)
    input_full = pd.concat([input_df, genre_input], axis=1)

    # Fill missing columns with 0 and order correctly
    for col in X.columns:
        if col not in input_full:
            input_full[col] = 0
    input_full = input_full[X.columns]

    prediction = model.predict(input_full)[0]
    return f"Predicted Vote Average: {prediction:.2f}"

# Build the Gradio interface
genre_list = list(mlb.classes_)
interface = gr.Interface(
    fn=predict_movie_score,
    inputs=[
        gr.Slider(0, 5000, step=1, label="Popularity"),
        gr.Slider(0, 10000, step=1, label="Vote Count"),
        gr.Number(label="Release Year", value=2023),
        gr.Slider(1, 12, step=1, label="Release Month"),
        gr.CheckboxGroup(choices=genre_list, label="Genres")
    ],
    outputs="text",
    title="🎬 Movie Score Predictor",
    description="Enter movie details to predict the vote average (final grade)."
)

# Launch the app
interface.launch()

"""Create a Prediction Function"""

def predict_vote_average(popularity, vote_count, release_year, release_month, selected_genres, model, mlb, feature_columns):
    """
    Predicts the vote average for a movie based on inputs.

    Parameters:
    - popularity: float
    - vote_count: int
    - release_year: int
    - release_month: int
    - selected_genres: list of str (e.g., ['Action', 'Comedy'])
    - model: trained sklearn model
    - mlb: fitted MultiLabelBinarizer
    - feature_columns: list of column names used during training (for alignment)

    Returns:
    - float: predicted vote average
    """
    import pandas as pd

    # Base numeric input
    input_data = {
        'popularity': popularity,
        'vote_count': vote_count,
        'release_year': release_year,
        'release_month': release_month
    }
    input_df = pd.DataFrame([input_data])

    # Genre one-hot encoding
    genre_input = pd.DataFrame([[1 if genre in selected_genres else 0 for genre in mlb.classes_]], columns=mlb.classes_)

    # Combine inputs
    input_full = pd.concat([input_df, genre_input], axis=1)

    # Add missing columns (if any) and reorder
    for col in feature_columns:
        if col not in input_full:
            input_full[col] = 0
    input_full = input_full[feature_columns]  # Ensure column order matches training

    # Predict
    prediction = model.predict(input_full)[0]
    return prediction

"""Create the Gradio Interface"""

# Step 1: Install required libraries (only once)
!pip install -q gradio pandas scikit-learn

# Step 2: Import required libraries
import pandas as pd
import numpy as np
import gradio as gr
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import MultiLabelBinarizer

# Step 3: Load and preprocess your data
df = pd.read_csv("/content/english_movies.csv")  # adjust path if needed

# Drop rows with missing target
df = df.dropna(subset=['vote_average'])

# Handle genres
df['genres'] = df['genres'].astype(str).apply(lambda x: x.split(', '))

# Convert date and extract year/month
df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
df['release_year'] = df['release_date'].dt.year
df['release_month'] = df['release_date'].dt.month

# One-hot encode genres
mlb = MultiLabelBinarizer()
genre_encoded = pd.DataFrame(mlb.fit_transform(df['genres']), columns=mlb.classes_)
df = pd.concat([df.drop(columns=['genres', 'title', 'overview', 'release_date']), genre_encoded], axis=1)

# Prepare features and target
X = df.drop(columns=['vote_average'])
y = df['vote_average']

# Train model
model = RandomForestRegressor(random_state=42)
model.fit(X, y)

# Save feature columns for prediction alignment
feature_columns = X.columns.tolist()

# Step 4: Define the prediction function
def predict_vote_average(popularity, vote_count, release_year, release_month, selected_genres):
    input_data = {
        'popularity': popularity,
        'vote_count': vote_count,
        'release_year': release_year,
        'release_month': release_month
    }
    input_df = pd.DataFrame([input_data])
    genre_input = pd.DataFrame([[1 if genre in selected_genres else 0 for genre in mlb.classes_]], columns=mlb.classes_)
    input_full = pd.concat([input_df, genre_input], axis=1)

    # Add missing columns and reorder
    for col in feature_columns:
        if col not in input_full:
            input_full[col] = 0
    input_full = input_full[feature_columns]

    prediction = model.predict(input_full)[0]
    return f"🎯 Predicted Vote Average: {prediction:.2f}"

# Step 5: Build the Gradio interface
interface = gr.Interface(
    fn=predict_vote_average,
    inputs=[
        gr.Slider(0, 5000, step=1, label="Popularity"),
        gr.Slider(0, 10000, step=1, label="Vote Count"),
        gr.Number(label="Release Year", value=2023),
        gr.Slider(1, 12, step=1, label="Release Month"),
        gr.CheckboxGroup(choices=list(mlb.classes_), label="Genres")
    ],
    outputs="text",
    title="🎬 Movie Score Predictor",
    description="Enter movie details to predict the expected vote average (like IMDb rating)."
)

# Step 6: Launch the app
interface.launch()
